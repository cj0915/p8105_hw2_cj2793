---
title: "p8105_hw2_cj2793"
author: "Chenyu Jin"
date: "2024-09-26"
output: github_document
---

# Problem 1

## Read and clean the data:

First, we should read the excel file, select the columns of interest and convert the entry variable from character (YES vs NO) to a logical variable:

```{r message = FALSE}
library(tidyverse)
cleaned_transit_df = read_csv(file = "hw2data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv", na = c("NA", ".", "")) |>
  janitor::clean_names() |>
  select("line", "station_name", "station_latitude", "station_longitude",
         c("route1":"route11"), "entry", "vending", "entrance_type", "ada") |>
  mutate(entry = ifelse(entry == "YES", TRUE, FALSE))

transit_row = nrow(cleaned_transit_df)

transit_row

transit_col = ncol(cleaned_transit_df)

transit_col
```

This data set contains information about entrances and exits for each subway station in the NYC transit system. The key variables include the subway line (`line`), station name (`station_name`), station location (`station_latitude` combined with `station_longitude`), routes served (`route1` ~ `route11`), whether entry is permitted (`entry`), vending machine availability (`vending`), entrance type (`entrance_type`), and ADA compliance (`ada`). In the cleaning process, we selected these relevant columns from the original data set and converted the `entry` variable from a character format (YES/NO) to a logical format (TRUE/FALSE). The resulting data set contains `r transit_col` columns and retains all `r transit_row` original rows from the source data. These data are not "tidy": route number should be a variable, as should route.

## Answer the following questions using these data:

1. How many distinct stations are there?

Here, We first create a new variable called 'Station', which is the full name of the Station, like '125th St 8th Avenue' and then do the analysis.

```{r}
cleaned_transit_df <- cleaned_transit_df |>
  mutate(Station = paste(station_name, line, sep = " "))

num_distinct_stations <- cleaned_transit_df |>
  distinct(Station) |>
  nrow()

num_distinct_stations
```

There are `r num_distinct_stations` stations.

2. How many stations are ADA compliant?

```{r}
ada_status <- cleaned_transit_df |>
  filter(ada == TRUE) |>
  distinct(Station) |>
  nrow()

ada_status
```

There are `r ada_status` stations with ADA compliant.

3. What proportion of station entrances / exits without vending allow entrance?

```{r}
wihout_vending <- cleaned_transit_df |>
  filter(vending == "NO")

entry_status <- wihout_vending |>
  filter(entry == TRUE) |>
  distinct(Station) |>
  nrow()

vending_status <- wihout_vending |> 
  distinct(Station) |>
  nrow()

proportion <- entry_status / vending_status

proportion
```

Proportion of station entrances / exits without vending allow entrance is `r proportion`.

## Reformat data and answer some questions about A train:

```{r}
cleaned_transit_df <- cleaned_transit_df |>
  mutate(across(starts_with("route"), as.character))

long_data <- cleaned_transit_df |>
  pivot_longer(route1:route11, 
               names_to = "route_number", 
               values_to = "route_name") |>
  filter(!is.na(route_name))

# How many distinct stations serve the A train?
A_train_stations <- long_data |>
  filter(route_name == "A") |>
  distinct(Station) |>
  nrow()

A_train_stations

# Of the stations that serve the A train, how many are ADA compliant?
ada_status_A <- long_data |>
  filter(route_name == "A", ada == TRUE) |>
  distinct(Station) |>
  nrow()

ada_status_A
```

`r A_train_stations` distinct stations serve the A train. Of the stations that serve the A train, `r ada_status_A` are ADA compliant.

# Problem 2

## Read and clean the Mr. Trash Wheel sheet:

```{r message = FALSE}
library(tidyverse)
library(readxl)

# specify the sheet in the Excel file and to omit non-data entries (rows with notes / figures; columns containing notes) using arguments in read_excel
file_path <- "hw2data/202409 Trash Wheel Collection Data.xlsx"
Mr_trashwheel_data <- read_excel(file_path, sheet = "Mr. Trash Wheel", skip = 1) |>
  janitor::clean_names()

Mr_trashwheel_data <- Mr_trashwheel_data[, -c(15, 16)] |>
  # omit rows that do not include dumpster-specific data
  filter(!is.na(dumpster)) |>
  # round the number of sports balls to the nearest integer and converts the result to an    integer variable
  mutate(sports_balls = as.integer(round(sports_balls))) |>
  # add an additional variable to keep track of Trash Wheel
  mutate(Trash_Wheel = "Mr. Trash Wheel") |>
  mutate(year = as.numeric(year))
```

## Read and clean the Professor Trash Wheel sheet:

```{r}
# specify the sheet in the Excel file and to omit non-data entries (rows with notes / figures; columns containing notes) using arguments in read_excel
file_path <- "hw2data/202409 Trash Wheel Collection Data.xlsx"
Prof_trashwheel_data <- read_excel(file_path, sheet = "Professor Trash Wheel", skip = 1) |>
  janitor::clean_names()

Prof_trashwheel_data <- Prof_trashwheel_data |>
  # omit rows that do not include dumpster-specific data
  filter(!is.na(dumpster)) |>
  # add an additional variable to keep track of Trash Wheel
  mutate(Trash_Wheel = "Professor Trash Wheel")
```

## Read and clean the Gwynnda Trash Wheel sheet:

```{r}
# specify the sheet in the Excel file and to omit non-data entries (rows with notes / figures; columns containing notes) using arguments in read_excel
file_path <- "hw2data/202409 Trash Wheel Collection Data.xlsx"
Gwy_trashwheel_data <- read_excel(file_path, sheet = "Gwynnda Trash Wheel", skip = 1) |>
  janitor::clean_names()

Gwy_trashwheel_data <- Gwy_trashwheel_data |>
  # omit rows that do not include dumpster-specific data
  filter(!is.na(dumpster)) |>
  # add an additional variable to keep track of Trash Wheel
  mutate(Trash_Wheel = "Gwynnda Trash Wheel")
```

## Combine all datasets into a single tidy dataset:

```{r}
combined_data <- bind_rows(Mr_trashwheel_data, Prof_trashwheel_data, Gwy_trashwheel_data)
```

## Write a paragraph about these data:

```{r}
# Count the number of observations in the data set (with duplication)
num_observations <- nrow(combined_data)

num_observations

# Total weight of trash collected by Professor Trash Wheel
Prof_trashwheel_weight <- combined_data |>
  filter(Trash_Wheel == "Professor Trash Wheel") |>
  summarize(Total_Weight = sum(weight_tons, na.rm = TRUE)) |>
  pull(Total_Weight)

Prof_trashwheel_weight

# Total number of cigarette butts collected by Gwynnda in June of 2022
Gwy_cigbutts_number <- combined_data |>
  filter(Trash_Wheel == "Gwynnda Trash Wheel" &
         month == "June" & 
         year == 2022) |>
  summarize(Total_Number = sum(cigarette_butts, na.rm = TRUE)) |>
  pull(Total_Number)

Gwy_cigbutts_number
```

The data set contains a total of `r num_observations` observations across three trash wheels: Mr. Trash Wheel, Professor Trash Wheel, and Gwynnda Trash Wheel. Each observation represents a record of the amount of trash collected for various categories, such as `plastic_bottles`, `polystyrene`, `cigarette_butts`, `glass_bottles`, and `sports_balls`. One key variable in the data set is `weight_tons`, which records the weight of trash collected in tons. For the available data, Professor Trash Wheel collected a total of `r Prof_trashwheel_weight` tons of trash. Additionally, Gwynnda Trash Wheel collected `r Gwy_cigbutts_number` cigarette butts in June of 2022.

# Problem 3

## Import, clean, tidy, and otherwise wrangle bakers, bakes and results datasets:

First, we should import the three data sets:

```{r message = FALSE}
library(tidyverse)
bakers_df = read_csv(file = "hw2data/bakers.csv") |>
  janitor::clean_names()

# For bakes_df, we get some potential NA value:
bakes_df = read.csv(file = "hw2data/bakes.csv", na = c("", "N/A", "UNKNOWN", "Unknown")) |>
  janitor::clean_names()

results_df = read.csv(file = "hw2data/results.csv") |>
  janitor::clean_names() |>
  slice(3:n()) |> # We only keep the data from the third row
  setNames(c("series", "episode", "baker", "technical", "result")) # Rename the columns
```

Now, all three data sets are tidy. We should then check for completeness and correctness across data sets.

## Check for completeness and correctness across datasets:

In the first place, we should check the consistency of data types as usual. Here, we find that the `series` and `episode` variables in `bakes_df`, `results_df` and `bakers_df` have different data formats, as a result, we should keep them consistent (I convert them to numeric type here).

```{r}
str(bakers_df)
str(bakes_df)
str(results_df)

bakes_df <- bakes_df |>
  mutate(series = as.numeric(series), episode = as.numeric(episode))

results_df <- results_df |>
  mutate(series = as.numeric(series), episode = as.numeric(episode))

bakers_df <- bakers_df |>
  rename(baker = baker_name) |> 
  mutate(series = as.numeric(series))

# Check the data structure again to make sure the consistency.
str(bakers_df)
str(bakes_df)
str(results_df)
```

We also notice that in `bakers_df`, `bakers` have full name recorded. However, in `bakes_df` and `results_df`, `bakers` only have first name recorded. We should make bakers' names consistent:

```{r}
bakers_df <- bakers_df |>
  mutate(baker = word(baker, 1))
```

Now, we have ensured the consistency of data sets. Then, let's use `anti_join` to check the completeness and correctness across data sets.

1. Let's check how many records from the `bakes_df` do not have a matching `series` and `baker` in the `bakers_df` and vice versa.

```{r}
anti_join(bakes_df, bakers_df, by = c("series", "baker"))
```

```{r}
anti_join(bakers_df, bakes_df, by = c("series", "baker"))
bb_number <- anti_join(bakers_df, bakes_df, by = c("series", "baker")) |>
  nrow()
```

Here we can see that `"Jo"` records from the `bakes_df` do not have a matching `series` and `baker` in the `bakers_df`; `r bb_number` record from the `bakers_df` do not have a matching `series` and `baker` in the `bakes_df`.

2. We should also check how many records from the `bakes_df` do not have a matching `series`, `episode`, and `baker` in the `results_df` and vice versa.

```{r}
anti_join(bakes_df, results_df, by = c("series", "episode", "baker"))
```

```{r}
rb_number <- anti_join(results_df, bakes_df, by = c("series", "episode", "baker")) |>
  nrow()
```

Here we can see that `"Jo"` records from the `bakes_df` do not have a matching `series`, `episode`, and `baker` in the `results_df`; `r rb_number` records from the `results_df` that do not have a matching `series`, `episode`, and `baker` in the `bakes_df`.

3. Last but not least, we should also check how many records from the `bakers_df` do not have a matching `series`and `baker` in the `results_df` and vice versa.

```{r}
anti_join(bakers_df, results_df, by = c("series", "baker"))
```

```{r}
anti_join(results_df, bakers_df, by = c("series", "baker"))
```

Here we can see that `Jo` records from the `bakers_df` do not have a matching `series` and `baker` in the `results_df`; `Joanne` record from the `results_df` do not have a matching `series` and `baker` in the `bakers_df`.

According to `anti_join`, we notice that in `bakes_df`, `"Jo"` should be `Jo`, without quotation marks. Let's change it:

```{r}
bakes_df[,"baker"] <- gsub('"', '', bakes_df[,"baker"])
```

Then, We should check how many records from the `bakes_results` do not have a matching `series`, `episode`, and `baker` in the `results_df` again after fix the quotation mark problem.

```{r}
anti_join(bakes_df, results_df, by = c("series", "episode", "baker"))
```

Here we can see that `Jo` records from the `bakes_df` still do not have a matching `series`, `episode`, and `baker` in the `results_df`, which means that in `results_df`, there is not a candidate called `Jo`. However, `Jo` in `bakes_df` and `bakers_df`is in series 2. In addition, we notice that in `results_df`, we have a candidate called `Joanne` in series 2 who also does not appear in `bakers_df`. As a result, we consider `Jo` as `Joanne`. As a result, we consider to change `Joanne` to `Jo` in `results_df`.

```{r}
results_df[, 3] <- gsub("Joanne", "Jo", results_df[, 3])
```

Also, we notice that `Diana` withdraw from the competition at episode 5 in series 5 (with WD result). As a result, we consider the results of `Diana` after episode 5 in series 5 as `NA`:

```{r}
results_df <- results_df |>
  mutate(result = if_else(baker == "Diana" & episode > 5, NA, result)) |>
  drop_na(result)
```

Now, let's use `anti_join` to check the completeness and correctness across data sets again after the modification.

```{r}
check_again1 <- anti_join(bakes_df, bakers_df, by = c("series", "baker")) |>
  nrow()

check_again2 <- anti_join(bakes_df, results_df, by = c("series", "episode", "baker")) |>
  nrow()

check_again3 <- anti_join(bakers_df, results_df, by = c("series", "baker")) |>
  nrow()

check_again1

check_again2

check_again3
```

From the results of checking, we can see that all observations in `bakes_df` show up in `bakers_df` and `results_df`; all obs in `bakers_df` show up in `results_df`. As a result, we can now join these data sets.

## Merge and organize a single, final dataset

```{r}
bakes_results <- results_df |>
  left_join(bakes_df, by = c("series", "episode", "baker"))

final_data <- bakes_results |>
  left_join(bakers_df, by = c("series", "baker")) |>
  select(series, episode, baker, baker_age, baker_occupation, hometown, 
         signature_bake, show_stopper, technical, result) |>
  arrange(series, episode, baker)
```

## Export the final data set

```{r}
write_csv(final_data, "hw2data/final_bakeoff_data.csv")
```

## Describe the data cleaning process and briefly discuss the final dataset
The data cleaning process involved importing and standardizing three data sets—`bakers`, `bakes`, and `results`—by cleaning column names and ensuring consistent data types, particularly for `series` and `episode`. A key challenge was unifying baker names, as `bakers_df` used full names while other data sets used first names, so we opted to use only first names for consistency. Another important choice was handling misleading data, such as replacing `"Jo"` with `Jo` in `bakes_df`; replacing `Joanne` with `Jo` in `results_df`; and adjusting results for `Diana`, who withdrew mid-competition. After ensuring completeness across data sets, they were merged into a final data set.

Once the data sets were merged, the columns were reorganized for better readability. The `baker_age`, `baker_occupation` and `hometown` columns were moved immediately after the `baker` column. To further enhance the structure of the data set, the data was sorted by series, episode, and baker, ensuring a logical flow that made it easy to track each progress of each series.

Finally, the cleaned and organized data set was exported as `final_bakeoff_data.csv`. The resulting data set includes detailed demographic information about each baker, such as their first name, age, occupation, and hometown, along with performance data for each episode in each series, including signature and showstopper bakes, technical rankings, and overall episode results. The logical structure of the data set allows for easy tracking of individual contestants and their journeys across seasons.

## Create a reader-friendly table

```{r}
starbakers_winners <- final_data |>
  filter(series %in% c("5", "6", "7", "8", "9", "10") & 
         result %in% c("STAR BAKER", "WINNER")) |>
  select(series, episode, baker, baker_age, baker_occupation, hometown, technical, result) |>
  arrange(series, episode, baker)

winners <- starbakers_winners |>
  filter(result == "WINNER")
```

From the results, we can conclude that most of the winners appear to be in their 30s, except for Nancy, who won Season 5 at the age of 60. Also, we notice that all winners have high ranks of technical skills (ranking at first or second place).
To our surprise, the competition is highly dynamic and the overall winner (like David in series 10) could never get star baker throughout the season.

## Import, clean, tidy, and organize the viewership data

```{r}
viewers_df = read.csv(file = "hw2data/viewers.csv") |>
  janitor::clean_names()
head(viewers_df, 10)
```

What was the average viewership in Season 1? In Season 5?

```{r}
Series1 = viewers_df |>
  pull(series_1)
S1_mean = mean(Series1, na.rm = TRUE)

Series5 = viewers_df |>
  pull(series_5)
S5_mean = mean(Series5, na.rm = TRUE)
```

The average viewership in Season 1 was `r S1_mean`, in Season 5 was `r S5_mean`.